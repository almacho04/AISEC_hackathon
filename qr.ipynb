{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac7658a9-b9c0-4f18-aa78-cb8feb41862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import fitz         # PyMuPDF\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from pyzbar.pyzbar import decode\n",
    "import json\n",
    "import validators\n",
    "import requests\n",
    "from urllib.parse import urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec0868a7-acb9-4669-83cc-254093630e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/tox/Desktop/hackathon\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "cwd = Path.cwd()\n",
    "print(\"Current directory:\", cwd)\n",
    "ROOT_DIR = Path.cwd()\n",
    "MODEL_PATH       = ROOT_DIR / \"best_yolo11_merged_4datasets.pt\"\n",
    "PDF_PATH         = ROOT_DIR / \"pdfs/АПЗ-41-чб.pdf\"\n",
    "OUTPUT_FOLDER    = ROOT_DIR / \"\"\n",
    "OUTPUT_IMAGE_DIR = OUTPUT_FOLDER / \"output_images\"\n",
    "OUTPUT_JSON_DIR  = OUTPUT_FOLDER / \"output_json\"\n",
    "OUTPUT_ANNOT_PDF = OUTPUT_FOLDER / f\"{PDF_PATH.stem}_qr_annotated.pdf\"\n",
    "\n",
    "# Create output folders\n",
    "OUTPUT_IMAGE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_JSON_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ccf4c24-63e9-4f0e-84f3-a2d54f7710e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded YOLO model with classes: {0: 'signature', 1: 'stamp', 2: 'qr'}\n"
     ]
    }
   ],
   "source": [
    "# Load the YOLO model\n",
    "model = YOLO(str(MODEL_PATH))\n",
    "CLASS_NAMES = model.names\n",
    "print(\"Loaded YOLO model with classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f20c277-2936-4c3b-86fb-fc9188e7fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path: Path, zoom: float = 2.0):\n",
    "    \"\"\"Convert PDF pages to images with specified zoom level\"\"\"\n",
    "    doc = fitz.open(str(pdf_path))\n",
    "    images = []\n",
    "    for page_idx in range(len(doc)):\n",
    "        page = doc.load_page(page_idx)\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
    "        if pix.n == 4:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        images.append((page_idx, img))\n",
    "    doc.close()\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "992b4e23-1e9a-45c5-a66f-022aae496f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_bgr, max_width=2000):\n",
    "    \"\"\"Resize image if width exceeds max_width\"\"\"\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    if w > max_width:\n",
    "        scale = max_width / w\n",
    "        img_bgr = cv2.resize(img_bgr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_AREA)\n",
    "    return img_bgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f8f66be-a79e-4419-8d04-df6e56a2c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_hash(img):\n",
    "    \"\"\"Compute perceptual hash for image comparison\"\"\"\n",
    "    # Resize to small size for comparison\n",
    "    small = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(small, cv2.COLOR_BGR2GRAY) if len(small.shape) == 3 else small\n",
    "    # Compute average hash\n",
    "    avg = gray.mean()\n",
    "    hash_val = (gray > avg).flatten()\n",
    "    return hash_val.tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19bdf70e-a94e-4541-ad08-041f17016849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_similar(img1, img2, threshold=0.9):\n",
    "    \"\"\"Check if two images are similar using histogram comparison\"\"\"\n",
    "    if img1.shape != img2.shape:\n",
    "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1\n",
    "    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2\n",
    "    \n",
    "    # Compute histograms\n",
    "    hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])\n",
    "    hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # Compare histograms\n",
    "    correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    return correlation > threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15195ab4-ffeb-411f-9063-ed31e496a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_qr_code_robust(qr_image):\n",
    "    \"\"\"Decode QR with preprocessing for better success rate\"\"\"\n",
    "    # Try pyzbar first\n",
    "    decoded_objects = decode(qr_image)\n",
    "    if decoded_objects:\n",
    "        return decoded_objects[0].data.decode('utf-8')\n",
    "    \n",
    "    # Fallback to OpenCV\n",
    "    qr_detector = cv2.QRCodeDetector()\n",
    "    data, bbox, _ = qr_detector.detectAndDecode(qr_image)\n",
    "    if data:\n",
    "        return data\n",
    "    \n",
    "    # Try with preprocessing\n",
    "    gray = cv2.cvtColor(qr_image, cv2.COLOR_BGR2GRAY) if len(qr_image.shape) == 3 else qr_image\n",
    "    preprocessed_versions = [\n",
    "        gray,\n",
    "        cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
    "        cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2),\n",
    "    ]\n",
    "    \n",
    "    for processed_img in preprocessed_versions:\n",
    "        decoded_objects = decode(processed_img)\n",
    "        if decoded_objects:\n",
    "            return decoded_objects[0].data.decode('utf-8')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc56e54d-be5c-46a5-8cff-39ed03f30b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_qr_content(qr_data: str, timeout: int = 5):\n",
    "    \"\"\"Validate QR code content (URL validation)\"\"\"\n",
    "    validation = {\n",
    "        'data': qr_data,\n",
    "        'is_url': False,\n",
    "        'url_valid': False,\n",
    "        'url_accessible': False,\n",
    "        'is_https': False,\n",
    "        'domain': None,\n",
    "        'status_code': None,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    if validators.url(qr_data):\n",
    "        validation['is_url'] = True\n",
    "        validation['url_valid'] = True\n",
    "        \n",
    "        parsed_url = urlparse(qr_data)\n",
    "        validation['is_https'] = parsed_url.scheme == 'https'\n",
    "        validation['domain'] = parsed_url.netloc\n",
    "        \n",
    "        try:\n",
    "            response = requests.head(qr_data, timeout=timeout, allow_redirects=True)\n",
    "            validation['url_accessible'] = True\n",
    "            validation['status_code'] = response.status_code\n",
    "            \n",
    "            if response.status_code >= 400:\n",
    "                validation['error'] = f\"HTTP {response.status_code}\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            validation['url_accessible'] = False\n",
    "            validation['error'] = str(e)\n",
    "    \n",
    "    return validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa291f29-2adc-4283-8e97-566b14b07a3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting PDF to images...\n",
      "\n",
      "Phase 1: Detecting all QR codes...\n",
      "Detected 21 QR codes total\n",
      "\n",
      "Phase 2: Grouping similar QR codes...\n",
      "Found 10 unique QR code(s)\n",
      "\n",
      "Phase 3: Decoding unique QR codes...\n",
      "  Decoding group 1/10 (1 instances)...\n",
      "  Decoding group 2/10 (5 instances)...\n",
      "  Decoding group 3/10 (6 instances)...\n",
      "  Decoding group 4/10 (1 instances)...\n",
      "  Decoding group 5/10 (1 instances)...\n",
      "  Decoding group 6/10 (1 instances)...\n",
      "  Decoding group 7/10 (1 instances)...\n",
      "  Decoding group 8/10 (3 instances)...\n",
      "  Decoding group 9/10 (1 instances)...\n",
      "  Decoding group 10/10 (1 instances)...\n",
      "Decoding complete!\n",
      "\n",
      "Phase 4: Validating unique QR codes...\n",
      "  Validating: https://www.armeta.ai/...\n",
      "\n",
      "Phase 5: Building results and annotating images...\n",
      "Annotation complete!\n"
     ]
    }
   ],
   "source": [
    "# Prepare JSON structures\n",
    "qr_detections = {}\n",
    "qr_validation = {}\n",
    "pdf_key = PDF_PATH.name\n",
    "\n",
    "# Convert PDF to images\n",
    "print(\"Converting PDF to images...\")\n",
    "pages = pdf_to_images(PDF_PATH, zoom=1)\n",
    "annotated_image_paths = []\n",
    "\n",
    "# PHASE 1: Detect all QR codes and collect their images\n",
    "print(\"\\nPhase 1: Detecting all QR codes...\")\n",
    "all_qr_crops = []  # Store all QR code crops\n",
    "qr_metadata = []   # Store metadata for each QR\n",
    "\n",
    "for (page_idx, img_bgr) in pages:\n",
    "    img_proc = preprocess_image(img_bgr, max_width=2000)\n",
    "    \n",
    "    # Detect QR codes using YOLO (class 2)\n",
    "    results = model.predict(source=img_proc, imgsz=1024, conf=0.25, iou=0.45, classes=[2], verbose=False)[0]\n",
    "    \n",
    "    if results.boxes is not None:\n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "        confs = results.boxes.conf.cpu().numpy()\n",
    "        \n",
    "        for idx, (box, conf) in enumerate(zip(boxes, confs)):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            \n",
    "            # Crop QR code region\n",
    "            qr_crop = img_bgr[int(y1):int(y2), int(x1):int(x2)]\n",
    "            \n",
    "            all_qr_crops.append(qr_crop)\n",
    "            qr_metadata.append({\n",
    "                'page': page_idx,\n",
    "                'index': idx,\n",
    "                'bbox': (x1, y1, x2, y2),\n",
    "                'confidence': float(conf),\n",
    "                'original_image': img_bgr  # Keep reference for drawing later\n",
    "            })\n",
    "\n",
    "print(f\"Detected {len(all_qr_crops)} QR codes total\")\n",
    "\n",
    "# PHASE 2: Group similar QR codes (find unique ones)\n",
    "print(\"\\nPhase 2: Grouping similar QR codes...\")\n",
    "unique_groups = []  # List of lists: each inner list contains indices of similar QRs\n",
    "\n",
    "for i, qr_crop in enumerate(all_qr_crops):\n",
    "    # Check if this QR is similar to any existing group\n",
    "    found_group = False\n",
    "    for group in unique_groups:\n",
    "        representative_idx = group[0]\n",
    "        representative_qr = all_qr_crops[representative_idx]\n",
    "        \n",
    "        if images_similar(qr_crop, representative_qr, threshold=0.9):\n",
    "            group.append(i)\n",
    "            found_group = True\n",
    "            break\n",
    "    \n",
    "    if not found_group:\n",
    "        # Create new group\n",
    "        unique_groups.append([i])\n",
    "\n",
    "print(f\"Found {len(unique_groups)} unique QR code(s)\")\n",
    "\n",
    "# PHASE 3: Decode only unique QR codes\n",
    "print(\"\\nPhase 3: Decoding unique QR codes...\")\n",
    "decoded_results = {}  # Map group_id -> decoded_data\n",
    "\n",
    "for group_idx, group in enumerate(unique_groups):\n",
    "    representative_idx = group[0]\n",
    "    representative_qr = all_qr_crops[representative_idx]\n",
    "    \n",
    "    print(f\"  Decoding group {group_idx+1}/{len(unique_groups)} ({len(group)} instances)...\")\n",
    "    decoded_data = decode_qr_code_robust(representative_qr)\n",
    "    \n",
    "    # Store decoded data for all QRs in this group\n",
    "    for qr_idx in group:\n",
    "        decoded_results[qr_idx] = decoded_data\n",
    "\n",
    "print(f\"Decoding complete!\")\n",
    "\n",
    "# PHASE 4: Validate unique decoded data\n",
    "print(\"\\nPhase 4: Validating unique QR codes...\")\n",
    "unique_decoded_data = set(d for d in decoded_results.values() if d is not None)\n",
    "validation_cache = {}  # Cache validation results\n",
    "\n",
    "for decoded_data in unique_decoded_data:\n",
    "    print(f\"  Validating: {decoded_data[:50]}...\")\n",
    "    validation_cache[decoded_data] = validate_qr_content(decoded_data)\n",
    "\n",
    "# PHASE 5: Build final results and annotate images\n",
    "print(\"\\nPhase 5: Building results and annotating images...\")\n",
    "all_qr_data = []\n",
    "\n",
    "for (page_idx, img_bgr) in pages:\n",
    "    page_key = f\"page_{page_idx+1}\"\n",
    "    orig_h, orig_w = img_bgr.shape[:2]\n",
    "    page_size = {\"width\": orig_w, \"height\": orig_h}\n",
    "    \n",
    "    qr_annotations = []\n",
    "    \n",
    "    # Find all QRs on this page\n",
    "    page_qr_indices = [i for i, meta in enumerate(qr_metadata) if meta['page'] == page_idx]\n",
    "    \n",
    "    for qr_idx in page_qr_indices:\n",
    "        meta = qr_metadata[qr_idx]\n",
    "        x1, y1, x2, y2 = meta['bbox']\n",
    "        width = float(x2 - x1)\n",
    "        height = float(y2 - y1)\n",
    "        area = width * height\n",
    "        \n",
    "        decoded_data = decoded_results.get(qr_idx)\n",
    "        validation = validation_cache.get(decoded_data) if decoded_data else None\n",
    "        \n",
    "        if decoded_data:\n",
    "            all_qr_data.append(decoded_data)\n",
    "        \n",
    "        ann_id = f\"qr_{page_idx+1}_{meta['index']+1}\"\n",
    "        qr_annotation = {\n",
    "            ann_id: {\n",
    "                \"category\": \"qr_code\",\n",
    "                \"bbox\": {\"x\": float(x1), \"y\": float(y1), \"width\": width, \"height\": height},\n",
    "                \"area\": area,\n",
    "                \"confidence\": meta['confidence'],\n",
    "                \"decoded_data\": decoded_data if decoded_data else \"DECODE_FAILED\",\n",
    "                \"validation\": validation\n",
    "            }\n",
    "        }\n",
    "        qr_annotations.append(qr_annotation)\n",
    "        \n",
    "        # Draw on image\n",
    "        color = (0, 255, 0) if decoded_data else (0, 0, 255)\n",
    "        cv2.rectangle(img_bgr, (int(x1), int(y1)), (int(x2), int(y2)), color, 3)\n",
    "        \n",
    "        label = decoded_data[:30] + \"...\" if decoded_data and len(decoded_data) > 30 else (decoded_data or \"FAILED\")\n",
    "        cv2.putText(img_bgr, label, (int(x1), int(y1)-10), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        if validation:\n",
    "            status = \"✓\" if validation['url_valid'] and validation['url_accessible'] else \"✗\"\n",
    "            cv2.putText(img_bgr, status, (int(x2)-30, int(y1)+30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "    \n",
    "    # Store page data\n",
    "    qr_detections.setdefault(pdf_key, {})[page_key] = {\n",
    "        \"annotations\": qr_annotations,\n",
    "        \"page_size\": page_size,\n",
    "        \"qr_count\": len(qr_annotations),\n",
    "        \"decoded_count\": len([a for a in qr_annotations if list(a.values())[0]['decoded_data'] != \"DECODE_FAILED\"])\n",
    "    }\n",
    "    \n",
    "    # Save annotated image\n",
    "    out_img_path = OUTPUT_IMAGE_DIR / f\"{PDF_PATH.stem}_page{page_idx+1}_qr.jpg\"\n",
    "    cv2.imwrite(str(out_img_path), img_bgr)\n",
    "    annotated_image_paths.append(out_img_path)\n",
    "\n",
    "print(f\"Annotation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca770a7-aba5-4c69-b447-9555b936a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29e8a369-fe68-45fd-ae79-6117397cf544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Status: PASS\n",
      "Total QR codes detected: 20\n",
      "Unique QR codes: 1\n",
      "Most common: https://www.armeta.ai/\n",
      "Appears 20 times\n",
      "\n",
      "Optimization:\n",
      "  Detected: 21 QR codes\n",
      "  Unique groups: 10\n",
      "  Decoded only: 10 times\n",
      "  Time saved: ~52.4%\n",
      "============================================================\n",
      "\n",
      "Saved annotated PDF: /home/tox/Desktop/hackathon/АПЗ-41-чб_qr_annotated.pdf\n",
      "Saved JSONs to: /home/tox/Desktop/hackathon/output_json\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "unique_qr_codes = set(all_qr_data)\n",
    "qr_frequency = Counter(all_qr_data)\n",
    "most_common = qr_frequency.most_common(1)[0] if qr_frequency else (None, 0)\n",
    "\n",
    "consistency_report = {\n",
    "    'total_qr_codes': len(all_qr_data),\n",
    "    'unique_qr_codes': len(unique_qr_codes),\n",
    "    'is_consistent': len(unique_qr_codes) == 1,\n",
    "    'most_common_qr': most_common[0],\n",
    "    'most_common_frequency': most_common[1],\n",
    "    'qr_frequency': dict(qr_frequency),\n",
    "    'status': 'PASS' if len(unique_qr_codes) == 1 else 'FAIL',\n",
    "    'optimization_stats': {\n",
    "        'total_qr_detected': len(all_qr_crops),\n",
    "        'unique_groups_found': len(unique_groups),\n",
    "        'decoding_operations': len(unique_groups),  # Only decoded this many times!\n",
    "        'time_saved_percentage': round((1 - len(unique_groups) / len(all_qr_crops)) * 100, 1) if all_qr_crops else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "qr_validation = {\n",
    "    pdf_key: {\n",
    "        \"detections\": qr_detections[pdf_key],\n",
    "        \"consistency\": consistency_report\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save JSONs\n",
    "with open(OUTPUT_JSON_DIR / \"qr_detections.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qr_detections, f, ensure_ascii=False, indent=2)\n",
    "with open(OUTPUT_JSON_DIR / \"qr_validation.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qr_validation, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Status: {consistency_report['status']}\")\n",
    "print(f\"Total QR codes detected: {consistency_report['total_qr_codes']}\")\n",
    "print(f\"Unique QR codes: {consistency_report['unique_qr_codes']}\")\n",
    "print(f\"Most common: {consistency_report['most_common_qr']}\")\n",
    "print(f\"Appears {consistency_report['most_common_frequency']} times\")\n",
    "print(\"\\nOptimization:\")\n",
    "print(f\"  Detected: {consistency_report['optimization_stats']['total_qr_detected']} QR codes\")\n",
    "print(f\"  Unique groups: {consistency_report['optimization_stats']['unique_groups_found']}\")\n",
    "print(f\"  Decoded only: {consistency_report['optimization_stats']['decoding_operations']} times\")\n",
    "print(f\"  Time saved: ~{consistency_report['optimization_stats']['time_saved_percentage']}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Merge images into annotated PDF\n",
    "if annotated_image_paths:\n",
    "    imgs = [Image.open(str(p)) for p in annotated_image_paths]\n",
    "    imgs[0].save(str(OUTPUT_ANNOT_PDF), save_all=True, append_images=imgs[1:])\n",
    "    print(f\"\\nSaved annotated PDF: {OUTPUT_ANNOT_PDF}\")\n",
    "    print(f\"Saved JSONs to: {OUTPUT_JSON_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f74bf4-28c2-402c-8016-7f85b873dd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
